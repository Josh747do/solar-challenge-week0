{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../data/sierraleone-bumbuna.csv')\n",
    "\n",
    "# Initial inspection\n",
    "print(\"ðŸ” DATA OVERVIEW\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b324e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: DATA PROFILING & MISSING VALUES ANALYSIS\n",
    "print(\"ðŸ“Š DATA PROFILING REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Basic Info\n",
    "print(\"1. DATASET BASIC INFORMATION:\")\n",
    "print(f\"   - Shape: {df.shape} (rows, columns)\")\n",
    "print(f\"   - Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 2. Data Types\n",
    "print(\"\\n2. DATA TYPES:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 3. Missing Values Analysis (REQUIRED BY ASSIGNMENT)\n",
    "print(\"\\n3. MISSING VALUES ANALYSIS:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_report = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "\n",
    "print(missing_report)\n",
    "\n",
    "# 4. Flag columns with >5% missing values (REQUIRED)\n",
    "high_missing = missing_percent[missing_percent > 5]\n",
    "print(f\"\\n4. COLUMNS WITH >5% MISSING VALUES ({len(high_missing)} found):\")\n",
    "if len(high_missing) > 0:\n",
    "    for col, percent in high_missing.items():\n",
    "        print(f\"   - {col}: {percent:.2f}% missing\")\n",
    "else:\n",
    "    print(\"   âœ… No columns with >5% missing values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02334a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: OUTLIER DETECTION & BASIC CLEANING\n",
    "print(\"ðŸ” OUTLIER DETECTION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Select columns for outlier detection (AS REQUIRED)\n",
    "outlier_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "available_columns = [col for col in outlier_columns if col in df.columns]\n",
    "\n",
    "print(f\"1. ANALYZING OUTLIERS IN: {available_columns}\")\n",
    "\n",
    "# 2. Calculate Z-scores for each column\n",
    "z_scores = {}\n",
    "outlier_counts = {}\n",
    "\n",
    "for col in available_columns:\n",
    "    # Remove NaN values for Z-score calculation\n",
    "    clean_data = df[col].dropna()\n",
    "    \n",
    "    if len(clean_data) > 0:\n",
    "        z_scores[col] = np.abs(stats.zscore(clean_data))\n",
    "        outlier_counts[col] = (z_scores[col] > 3).sum()\n",
    "    else:\n",
    "        outlier_counts[col] = 0\n",
    "\n",
    "# 3. Display outlier summary\n",
    "print(\"\\n2. OUTLIER SUMMARY (|Z-score| > 3):\")\n",
    "outlier_report = pd.DataFrame({\n",
    "    'Column': list(outlier_counts.keys()),\n",
    "    'Outlier Count': list(outlier_counts.values()),\n",
    "    'Total Rows': [len(df[col].dropna()) for col in available_columns],\n",
    "    'Outlier %': [f\"{(outlier_counts[col]/len(df[col].dropna()))*100:.2f}%\" \n",
    "                  for col in available_columns]\n",
    "})\n",
    "\n",
    "print(outlier_report)\n",
    "\n",
    "# 4. Flag rows with multiple outliers (ADVANCED INSIGHT)\n",
    "print(\"\\n3. ROWS WITH MULTIPLE OUTLIERS:\")\n",
    "outlier_flags = pd.DataFrame()\n",
    "\n",
    "for col in available_columns:\n",
    "    if col in z_scores:\n",
    "        outlier_flags[col] = z_scores[col] > 3\n",
    "\n",
    "# Count outliers per row\n",
    "outlier_flags['total_outliers'] = outlier_flags.sum(axis=1)\n",
    "multi_outlier_rows = (outlier_flags['total_outliers'] > 1).sum()\n",
    "\n",
    "print(f\"   - Rows with >1 outlier: {multi_outlier_rows}\")\n",
    "print(f\"   - This might indicate sensor malfunctions or extreme weather events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: DATA CLEANING & EXPORT\n",
    "print(\"ðŸ§¹ DATA CLEANING & PREPARATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a clean copy of the dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"1. HANDLING MISSING VALUES:\")\n",
    "# Strategy: Median imputation for numeric columns (AS REQUIRED)\n",
    "numeric_columns = df_clean.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in numeric_columns:\n",
    "    missing_before = df_clean[col].isna().sum()\n",
    "    if missing_before > 0:\n",
    "        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "        print(f\"   - {col}: Filled {missing_before} missing values with median\")\n",
    "\n",
    "print(\"\\n2. HANDLING OUTLIERS:\")\n",
    "# Option 1: Cap outliers (more conservative than removing)\n",
    "for col in available_columns:\n",
    "    if col in df_clean.columns and col in z_scores:\n",
    "        # Find the outlier bounds\n",
    "        clean_data = df[col].dropna()\n",
    "        if len(clean_data) > 0:\n",
    "            Q1 = clean_data.quantile(0.25)\n",
    "            Q3 = clean_data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Cap outliers\n",
    "            outliers_before = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()\n",
    "            df_clean[col] = np.clip(df_clean[col], lower_bound, upper_bound)\n",
    "            outliers_after = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()\n",
    "            \n",
    "            if outliers_before > 0:\n",
    "                print(f\"   - {col}: Capped {outliers_before} outliers using IQR method\")\n",
    "\n",
    "print(\"\\n3. DATA QUALITY SUMMARY:\")\n",
    "print(f\"   - Original shape: {df.shape}\")\n",
    "print(f\"   - Cleaned shape: {df_clean.shape}\")\n",
    "print(f\"   - Missing values removed: {(df.isna().sum().sum() - df_clean.isna().sum().sum())}\")\n",
    "print(f\"   - Memory optimized: {df.memory_usage(deep=True).sum() / 1024**2:.2f}MB â†’ {df_clean.memory_usage(deep=True).sum() / 1024**2:.2f}MB\")\n",
    "\n",
    "# 4. EXPORT CLEANED DATA (REQUIRED)\n",
    "print(\"\\n4. EXPORTING CLEANED DATA:\")\n",
    "clean_file_path = '../data/benin_clean.csv'\n",
    "df_clean.to_csv(clean_file_path, index=False)\n",
    "print(f\"   âœ… Cleaned data exported to: {clean_file_path}\")\n",
    "print(f\"   - File contains {len(df_clean)} rows and {len(df_clean.columns)} columns\")\n",
    "\n",
    "# 5. VERIFICATION\n",
    "print(\"\\n5. DATA QUALITY VERIFICATION:\")\n",
    "print(f\"   - Missing values in cleaned data: {df_clean.isna().sum().sum()}\")\n",
    "print(f\"   - Data types preserved: {len(df_clean.columns) == len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: TIME SERIES ANALYSIS\n",
    "print(\"â° TIME SERIES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Convert Timestamp to datetime and set as index\n",
    "print(\"1. PREPARING TIME SERIES DATA:\")\n",
    "df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'])\n",
    "df_clean.set_index('Timestamp', inplace=True)\n",
    "print(f\"   - Time range: {df_clean.index.min()} to {df_clean.index.max()}\")\n",
    "print(f\"   - Total duration: {(df_clean.index.max() - df_clean.index.min()).days} days\")\n",
    "\n",
    "# 2. Solar Radiation Patterns Over Time\n",
    "print(\"\\n2. SOLAR RADIATION TIME SERIES:\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Solar Radiation Patterns - Benin', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot GHI (Global Horizontal Irradiance)\n",
    "if 'GHI' in df_clean.columns:\n",
    "    df_clean['GHI'].resample('D').mean().plot(ax=axes[0,0], color='orange', linewidth=1)\n",
    "    axes[0,0].set_title('Daily Average GHI')\n",
    "    axes[0,0].set_ylabel('GHI (W/mÂ²)')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot DNI (Direct Normal Irradiance)\n",
    "if 'DNI' in df_clean.columns:\n",
    "    df_clean['DNI'].resample('D').mean().plot(ax=axes[0,1], color='red', linewidth=1)\n",
    "    axes[0,1].set_title('Daily Average DNI')\n",
    "    axes[0,1].set_ylabel('DNI (W/mÂ²)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot DHI (Diffuse Horizontal Irradiance)\n",
    "if 'DHI' in df_clean.columns:\n",
    "    df_clean['DHI'].resample('D').mean().plot(ax=axes[1,0], color='blue', linewidth=1)\n",
    "    axes[1,0].set_title('Daily Average DHI')\n",
    "    axes[1,0].set_ylabel('DHI (W/mÂ²)')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot Temperature\n",
    "if 'Tamb' in df_clean.columns:\n",
    "    df_clean['Tamb'].resample('D').mean().plot(ax=axes[1,1], color='green', linewidth=1)\n",
    "    axes[1,1].set_title('Daily Average Temperature')\n",
    "    axes[1,1].set_ylabel('Temperature (Â°C)')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Monthly Patterns (Seasonal Analysis)\n",
    "print(\"\\n3. SEASONAL PATTERNS:\")\n",
    "df_clean['Month'] = df_clean.index.month\n",
    "\n",
    "monthly_patterns = df_clean.groupby('Month')[['GHI', 'DNI', 'DHI', 'Tamb']].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for column in ['GHI', 'DNI', 'DHI']:\n",
    "    if column in monthly_patterns.columns:\n",
    "        plt.plot(monthly_patterns.index, monthly_patterns[column], marker='o', label=column)\n",
    "\n",
    "plt.title('Monthly Average Solar Radiation Patterns')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Radiation (W/mÂ²)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.show()\n",
    "\n",
    "# 4. Daily Patterns (Hourly Analysis)\n",
    "print(\"\\n4. DAILY PATTERNS:\")\n",
    "df_clean['Hour'] = df_clean.index.hour\n",
    "\n",
    "# Only analyze if we have hourly data\n",
    "if len(df_clean) > 24*7:  # At least a week of hourly data\n",
    "    hourly_patterns = df_clean.groupby('Hour')[['GHI', 'DNI', 'DHI']].mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for column in ['GHI', 'DNI', 'DHI']:\n",
    "        if column in hourly_patterns.columns:\n",
    "            plt.plot(hourly_patterns.index, hourly_patterns[column], marker='o', label=column)\n",
    "    \n",
    "    plt.title('Average Daily Solar Radiation Cycle')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Radiation (W/mÂ²)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"   - Insufficient data for hourly analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c375148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: CORRELATION & RELATIONSHIP ANALYSIS\n",
    "print(\"ðŸ“ˆ CORRELATION & RELATIONSHIP ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Correlation Heatmap (REQUIRED)\n",
    "print(\"1. CORRELATION HEATMAP:\")\n",
    "correlation_columns = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB', 'Tamb', 'RH', 'WS', 'BP']\n",
    "available_corr_columns = [col for col in correlation_columns if col in df_clean.columns]\n",
    "\n",
    "if len(available_corr_columns) >= 3:  # Need at least 3 columns for meaningful heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    corr_matrix = df_clean[available_corr_columns].corr()\n",
    "    \n",
    "    # Create heatmap with annotations\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Mask upper triangle\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
    "                square=True, fmt='.2f', cbar_kws={'shrink': .8})\n",
    "    plt.title('Solar Data Correlation Matrix - Benin', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify strong correlations\n",
    "    print(\"\\n2. STRONG CORRELATIONS (|r| > 0.7):\")\n",
    "    strong_corrs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                strong_corrs.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j],\n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    if strong_corrs:\n",
    "        for col1, col2, corr in strong_corrs:\n",
    "            print(f\"   - {col1} â†” {col2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"   - No very strong correlations found\")\n",
    "else:\n",
    "    print(\"   - Not enough columns for correlation analysis\")\n",
    "\n",
    "# 3. Scatter Plots (REQUIRED)\n",
    "print(\"\\n3. SCATTER PLOT RELATIONSHIPS:\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Solar Radiation Relationships - Benin', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Wind Speed vs GHI\n",
    "if all(col in df_clean.columns for col in ['WS', 'GHI']):\n",
    "    axes[0,0].scatter(df_clean['WS'], df_clean['GHI'], alpha=0.5, s=1)\n",
    "    axes[0,0].set_xlabel('Wind Speed (m/s)')\n",
    "    axes[0,0].set_ylabel('GHI (W/mÂ²)')\n",
    "    axes[0,0].set_title('Wind Speed vs Solar Radiation')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Wind Gust vs GHI\n",
    "if all(col in df_clean.columns for col in ['WSgust', 'GHI']):\n",
    "    axes[0,1].scatter(df_clean['WSgust'], df_clean['GHI'], alpha=0.5, s=1, color='orange')\n",
    "    axes[0,1].set_xlabel('Wind Gust (m/s)')\n",
    "    axes[0,1].set_ylabel('GHI (W/mÂ²)')\n",
    "    axes[0,1].set_title('Wind Gust vs Solar Radiation')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Relative Humidity vs Temperature\n",
    "if all(col in df_clean.columns for col in ['RH', 'Tamb']):\n",
    "    axes[1,0].scatter(df_clean['RH'], df_clean['Tamb'], alpha=0.5, s=1, color='green')\n",
    "    axes[1,0].set_xlabel('Relative Humidity (%)')\n",
    "    axes[1,0].set_ylabel('Temperature (Â°C)')\n",
    "    axes[1,0].set_title('Humidity vs Temperature')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Relative Humidity vs GHI\n",
    "if all(col in df_clean.columns for col in ['RH', 'GHI']):\n",
    "    axes[1,1].scatter(df_clean['RH'], df_clean['GHI'], alpha=0.5, s=1, color='red')\n",
    "    axes[1,1].set_xlabel('Relative Humidity (%)')\n",
    "    axes[1,1].set_ylabel('GHI (W/mÂ²)')\n",
    "    axes[1,1].set_title('Humidity vs Solar Radiation')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Key Insights from Relationships\n",
    "print(\"\\n4. KEY INSIGHTS:\")\n",
    "insights = []\n",
    "\n",
    "# Wind impact\n",
    "if 'WS' in df_clean.columns and 'GHI' in df_clean.columns:\n",
    "    wind_ghi_corr = df_clean['WS'].corr(df_clean['GHI'])\n",
    "    insights.append(f\"Wind speed has { 'positive' if wind_ghi_corr > 0 else 'negative' } correlation with GHI (r={wind_ghi_corr:.3f})\")\n",
    "\n",
    "# Humidity impact\n",
    "if 'RH' in df_clean.columns and 'GHI' in df_clean.columns:\n",
    "    rh_ghi_corr = df_clean['RH'].corr(df_clean['GHI'])\n",
    "    insights.append(f\"Humidity has { 'positive' if rh_ghi_corr > 0 else 'negative' } correlation with GHI (r={rh_ghi_corr:.3f})\")\n",
    "\n",
    "# Temperature relationships\n",
    "if 'Tamb' in df_clean.columns and 'GHI' in df_clean.columns:\n",
    "    temp_ghi_corr = df_clean['Tamb'].corr(df_clean['GHI'])\n",
    "    insights.append(f\"Temperature has { 'positive' if temp_ghi_corr > 0 else 'negative' } correlation with GHI (r={temp_ghi_corr:.3f})\")\n",
    "\n",
    "for insight in insights:\n",
    "    print(f\"   - {insight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: WIND & DISTRIBUTION ANALYSIS\n",
    "print(\"ðŸŒ¬ï¸ WIND & DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Histograms for GHI and WS (REQUIRED)\n",
    "print(\"1. DISTRIBUTION HISTOGRAMS:\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# GHI Histogram\n",
    "if 'GHI' in df_clean.columns:\n",
    "    axes[0].hist(df_clean['GHI'].dropna(), bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[0].set_xlabel('GHI (W/mÂ²)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('GHI Distribution')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Wind Speed Histogram  \n",
    "if 'WS' in df_clean.columns:\n",
    "    axes[1].hist(df_clean['WS'].dropna(), bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[1].set_xlabel('Wind Speed (m/s)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Wind Speed Distribution')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Basic Wind Rose (Simplified - radial bar plot alternative)\n",
    "print(\"2. WIND DIRECTION ANALYSIS:\")\n",
    "if 'WD' in df_clean.columns:\n",
    "    # Group wind directions into sectors\n",
    "    wind_directions = df_clean['WD'].dropna()\n",
    "    direction_bins = pd.cut(wind_directions, bins=8, labels=['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'])\n",
    "    direction_counts = direction_bins.value_counts().sort_index()\n",
    "    \n",
    "    # Create radial-like bar plot\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    angles = np.linspace(0, 2*np.pi, len(direction_counts), endpoint=False)\n",
    "    plt.polar(angles, direction_counts.values, marker='o')\n",
    "    plt.title('Wind Direction Distribution', size=14)\n",
    "    plt.xticks(angles, direction_counts.index)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"   - Most common wind direction: {direction_counts.idxmax()}\")\n",
    "    print(f\"   - Least common wind direction: {direction_counts.idxmin()}\")\n",
    "else:\n",
    "    print(\"   - Wind direction data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cae73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: TEMPERATURE ANALYSIS  \n",
    "print(\"ðŸŒ¡ï¸ TEMPERATURE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"1. RELATIVE HUMIDITY INFLUENCE ON TEMPERATURE AND RADIATION:\")\n",
    "\n",
    "# RH vs Temperature relationship\n",
    "if all(col in df_clean.columns for col in ['RH', 'Tamb']):\n",
    "    rh_temp_corr = df_clean['RH'].corr(df_clean['Tamb'])\n",
    "    print(f\"   - RH vs Temperature correlation: {rh_temp_corr:.3f}\")\n",
    "    \n",
    "# RH vs GHI relationship  \n",
    "if all(col in df_clean.columns for col in ['RH', 'GHI']):\n",
    "    rh_ghi_corr = df_clean['RH'].corr(df_clean['GHI'])\n",
    "    print(f\"   - RH vs GHI correlation: {rh_ghi_corr:.3f}\")\n",
    "\n",
    "# Temperature ranges and solar efficiency\n",
    "if 'Tamb' in df_clean.columns:\n",
    "    temp_stats = df_clean['Tamb'].describe()\n",
    "    print(f\"   - Temperature range: {temp_stats['min']:.1f}Â°C to {temp_stats['max']:.1f}Â°C\")\n",
    "    print(f\"   - Average temperature: {temp_stats['mean']:.1f}Â°C\")\n",
    "    \n",
    "    # Optimal temperature range for solar panels (typically 15-35Â°C)\n",
    "    optimal_temp = df_clean[(df_clean['Tamb'] >= 15) & (df_clean['Tamb'] <= 35)]\n",
    "    optimal_percent = (len(optimal_temp) / len(df_clean)) * 100\n",
    "    print(f\"   - {optimal_percent:.1f}% of time in optimal solar panel temperature range (15-35Â°C)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d69628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: BUBBLE CHART (REQUIRED)\n",
    "print(\"ðŸ«§ BUBBLE CHART ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if all(col in df_clean.columns for col in ['GHI', 'Tamb', 'RH']):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create bubble chart: GHI vs Tamb with bubble size = RH\n",
    "    scatter = plt.scatter(df_clean['Tamb'], df_clean['GHI'], \n",
    "                         s=df_clean['RH']/2,  # Scale RH for bubble size\n",
    "                         alpha=0.6, c=df_clean['RH'], cmap='viridis')\n",
    "    \n",
    "    plt.colorbar(scatter, label='Relative Humidity (%)')\n",
    "    plt.xlabel('Temperature (Â°C)')\n",
    "    plt.ylabel('GHI (W/mÂ²)')\n",
    "    plt.title('GHI vs Temperature (Bubble size = Relative Humidity)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"   - Bubble chart shows relationship between GHI, Temperature, and Humidity\")\n",
    "    print(\"   - Larger bubbles indicate higher humidity conditions\")\n",
    "else:\n",
    "    print(\"   - Required columns (GHI, Tamb, RH) not available for bubble chart\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
